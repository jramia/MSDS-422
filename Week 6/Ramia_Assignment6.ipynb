{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ramia_Assignment6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:** This assignment involves fitting a neural network to the MNIST data, testing alternative network structures. Tested neural network structures will be explored within a benchmark experiment, a factorial design with two levels on each of two experimental factors (a 2x2 completely crossed design). We will assess classification performance of accuracy and processing time of these models to determine which one to recommend for optical character recognition.\n",
    "\n",
    "We find that, while adding more layers does not seem to improve the accuracy of these models tremendously, more nodes per layer does. Further, processing time tends to increase with added complexity, though the model with fewer layers and 20 nodes per layer runs slower than the model with a greater number of layers, oddly enough. Thus, I conclude that the model with five layers of 20 nodes each is the model that should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1)\n",
    "    mnist.target = mnist.target.astype(np.int64)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist['data'][:60000]\n",
    "y_train = mnist['target'][:60000]\n",
    "\n",
    "X_test = mnist['data'][60000:]\n",
    "y_test = mnist['target'][60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type and shape of the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train object: <class 'numpy.ndarray'> (60000, 784)\n",
      "\n",
      "y_train object: <class 'numpy.ndarray'> (60000,)\n",
      "\n",
      "X_test object: <class 'numpy.ndarray'> (10000, 784)\n",
      "\n",
      "y_test object: <class 'numpy.ndarray'> (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('\\nX_train object:', type(X_train), X_train.shape)    \n",
    "print('\\ny_train object:', type(y_train),  y_train.shape)  \n",
    "print('\\nX_test object:', type(X_test),  X_test.shape)  \n",
    "print('\\ny_test object:', type(y_test),  y_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "RANDOM_SEED = 9999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define four methods to be benchmarked in our experiment. Here we will be comparing networks of varying structures. However, there are plenty of other hyperparameters that could be compared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ANN-2-Layers-10-Nodes-per-Layer',\n",
    "         'ANN-2-Layers-20-Nodes-per-Layer',\n",
    "         'ANN-5-Layers-10-Nodes-per-Layer',\n",
    "         'ANN-5-Layers-20-Nodes-per-Layer']\n",
    "\n",
    "layers = [2, 2, 5, 5]\n",
    "nodes_per_layer = [10, 20, 10, 20]\n",
    "treatment_condition = [(10, 10), \n",
    "                       (20, 20), \n",
    "                       (10, 10, 10, 10, 10), \n",
    "                       (20, 20, 20, 20, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    MLPClassifier(hidden_layer_sizes=treatment_condition[0], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "    MLPClassifier(hidden_layer_sizes=treatment_condition[1], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "    MLPClassifier(hidden_layer_sizes=treatment_condition[2], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "    MLPClassifier(hidden_layer_sizes=treatment_condition[3], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and score each model iteratively:\n",
    "\n",
    "*Note:* Using deprecated time functions will produce warnings. These are not errors, however, and will not prevent your code from running. To prevent these warnings from occuring, use a recommended time function instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-2-Layers-10-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time (seconds): 490.651651\n",
      "\n",
      "Training set accuracy: 0.941150\n",
      "\n",
      "Test set accuracy: 0.925000\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-2-Layers-20-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time (seconds): 670.844476\n",
      "\n",
      "Training set accuracy: 0.970850\n",
      "\n",
      "Test set accuracy: 0.942500\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-5-Layers-10-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(10, 10, 10, 10, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time (seconds): 555.676125\n",
      "\n",
      "Training set accuracy: 0.962017\n",
      "\n",
      "Test set accuracy: 0.934700\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-5-Layers-20-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20, 20, 20, 20, 20), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/Cellar/ipython/7.4.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time (seconds): 624.406146\n",
      "\n",
      "Training set accuracy: 0.984217\n",
      "\n",
      "Test set accuracy: 0.947400\n"
     ]
    }
   ],
   "source": [
    "index_for_method = 0 \n",
    "training_performance_results = []\n",
    "test_performance_results = []\n",
    "processing_time = []\n",
    "   \n",
    "for name, method in zip(names, methods):\n",
    "    print('\\n------------------------------------')\n",
    "    print('\\nMethod:', name)\n",
    "    print('\\n  Specification of method:', method)\n",
    "    start_time = time.clock()\n",
    "    method.fit(X_train, y_train)\n",
    "    end_time = time.clock()\n",
    "    runtime = end_time - start_time  # seconds of wall-clock time \n",
    "    print(\"\\nProcessing time (seconds): %f\" % runtime)        \n",
    "    processing_time.append(runtime)\n",
    "\n",
    "    # mean accuracy of prediction in training set\n",
    "    training_performance = method.score(X_train, y_train)\n",
    "    print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
    "    training_performance_results.append(training_performance)\n",
    "\n",
    "    # mean accuracy of prediction in test set\n",
    "    test_performance = method.score(X_test, y_test)\n",
    "    print(\"\\nTest set accuracy: %f\" % test_performance)\n",
    "    test_performance_results.append(test_performance)\n",
    "                \n",
    "    index_for_method += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the results for final report using OrderedDict to preserve the order of variables in DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark Experiment: Scikit Learn Artificial Neural Networks\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Nodes per Layer</th>\n",
       "      <th>Processing Time</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN-2-Layers-10-Nodes-per-Layer</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>490.651651</td>\n",
       "      <td>0.941150</td>\n",
       "      <td>0.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANN-2-Layers-20-Nodes-per-Layer</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>670.844476</td>\n",
       "      <td>0.970850</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANN-5-Layers-10-Nodes-per-Layer</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>555.676125</td>\n",
       "      <td>0.962017</td>\n",
       "      <td>0.9347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANN-5-Layers-20-Nodes-per-Layer</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>624.406146</td>\n",
       "      <td>0.984217</td>\n",
       "      <td>0.9474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Method Name  Layers  Nodes per Layer  Processing Time  \\\n",
       "0  ANN-2-Layers-10-Nodes-per-Layer       2               10       490.651651   \n",
       "1  ANN-2-Layers-20-Nodes-per-Layer       2               20       670.844476   \n",
       "2  ANN-5-Layers-10-Nodes-per-Layer       5               10       555.676125   \n",
       "3  ANN-5-Layers-20-Nodes-per-Layer       5               20       624.406146   \n",
       "\n",
       "   Training Set Accuracy  Test Set Accuracy  \n",
       "0               0.941150             0.9250  \n",
       "1               0.970850             0.9425  \n",
       "2               0.962017             0.9347  \n",
       "3               0.984217             0.9474  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(OrderedDict([('Method Name', names),\n",
    "                        ('Layers', layers),\n",
    "                        ('Nodes per Layer', nodes_per_layer),\n",
    "                        ('Processing Time', processing_time),\n",
    "                        ('Training Set Accuracy', training_performance_results),\n",
    "                        ('Test Set Accuracy', test_performance_results)]))\n",
    "\n",
    "print('\\nBenchmark Experiment: Scikit Learn Artificial Neural Networks\\n')\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** These models performed fairly well, though these results are somewhat disappointing for a neural network. We were able to achieve greater results using a random forest in the previous assignment. Further, it appears all four models are slightly overfitting the training data.\n",
    "\n",
    "To improve accuracy and prevent overfitting, neural networks provide what seems like an infinite amount of flexibility in their hyperparameters. There are many other more complex models that deserve to be benchmarked alongside these simpler models. For instance, one might increase the complexity of the model structure, explore different activation functions, or add regularization methods. Further, one warning we received while running these models stated that the models failed to converge before the max iterations were met. Allowing the models to run for longer could also improve performance.\n",
    "\n",
    "Of course, adjusting hyperparameters could come at the expense of time, which was not terrible for these simple models (the longest a model took to run was just over ten minutes). For now we are left to recommend the model with five layers of 20 nodes each for the financial institution to use for their optical character recognition problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
