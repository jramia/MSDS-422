{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ramia_Assignment5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:** For this assignment we will develop a classifier that may be used to predict which of the 10 digits is being written in the MNIST dataset. We will employ two separate programs for this study: (1) random forest classifier with the full set of features, (2) principal components analysis and random forest classifier using the principal components. We will compare test set performance across the two modeling approaches, as well as evaluate the time required to perform each approach.\n",
    "\n",
    "The results of this study show that the random forest classifier outperformed the classifier trained on the decomposed data in both time and accuracy. This may be characteristic of the dataset, the model and the training algorithm rather than the approach itself. In future studies I recommend trying both appraoches to test how they perform in those particular circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1)\n",
    "    mnist.target = mnist.target.astype(np.int64)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist['data'][:60000]\n",
    "y_train = mnist['target'][:60000]\n",
    "\n",
    "X_test = mnist['data'][60000:]\n",
    "y_test = mnist['target'][60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(max_features='sqrt',\\\n",
    "                                 bootstrap=True,\\\n",
    "                                 n_estimators=10,\\\n",
    "                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "td = t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 3.65s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training took {:.2f}s\".format(td))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96455317, 0.98989011, 0.94696608, 0.9261811 , 0.94613821,\n",
       "       0.92997199, 0.96620908, 0.9546798 , 0.92909281, 0.92607393])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use PCA to reduce the dataset's dimensionality, with an explained variance ratio of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "t2 = time.time()\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "t3 = time.time()\n",
    "td2 = t3 - t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition took 5.12s\n"
     ]
    }
   ],
   "source": [
    "print(\"Decomposition took {:.2f}s\".format(td2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a new Random Forest classifier on the reduced dataset and see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf2 = RandomForestClassifier(max_features='sqrt',\\\n",
    "                                  bootstrap=True,\\\n",
    "                                  n_estimators=10,\\\n",
    "                                  random_state=1)\n",
    "t4 = time.time()\n",
    "rnd_clf2.fit(X_train_reduced, y_train)\n",
    "t5 = time.time()\n",
    "td3 = t5 - t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 6.98s\n",
      "Total took 12.10s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training took {:.2f}s\".format(td3))\n",
    "print(\"Total took {:.2f}s\".format(td2 + td3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training actually takes nearly twice as long to run now. Total time including decomposition takes nearly four times as long as training a random forest classifier on the raw data alone.\n",
    "\n",
    "Dimensionality reduction does not always lead to faster training time. It depends on the dataset, the model and the training algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, evaluate the new random forest classifier on the test set to compare to the previous classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92398815, 0.96858639, 0.88676541, 0.8647619 , 0.87227723,\n",
       "       0.84306987, 0.9199157 , 0.9044335 , 0.84677856, 0.86036961])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "y_pred = rnd_clf2.predict(X_test_reduced)\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common for performance to drop slightly when reducing dimensionality, because we do lose some useful signal in the process. However, the performance drop is rather severe in this case. So PCA really did not help: it slowed down training and reduced performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Although PCA did not help in this particular case, future studies should still attempt both appraoches in order to assess how they perform given a new dataset, model and training algorithm. Unsupervised learning is an iterative process that requires exploration of the results. One should not take the performance of this particular application of PCA as true for all cases. Instead, any quality data scientist would use their inquisitive spirit to explore the merits of PCA for each task at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
